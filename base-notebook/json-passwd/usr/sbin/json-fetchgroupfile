#!/usr/bin/python3
# Generate /etc/sssd/group from a remote JSON source.

#########################################################################
### Configuration #######################################################
#########################################################################

import filecmp, os

if 'JPCONF' in os.environ:
    configFile = os.environ['JPCONF']
else:
    configFile = '/etc/json-passwd/config'

#########################################################################
### Declarations ########################################################
#########################################################################

import datetime, json, optparse, os.path, re, requests, shlex, \
    shutil, subprocess, sys, syslog, tempfile, time
from distutils.version import StrictVersion

requiredElements = ['gid', 'users']

tmpDir = tempfile.mkdtemp()

#########################################################################
### Subroutines #########################################################
#########################################################################

def cmd_external_stderr_to_return(cmdline):
    """
    Run a command with subprocess.Popen(), and send the first line of
    STDERR as a return value, and leave STDOUT to go to actual STDOUT.
    """
    proc = subprocess.Popen(shlex.split(cmdline.encode('ascii')),
        stderr=subprocess.PIPE)
    (out, err) = proc.communicate()
    value = err.rstrip()
    return value

def loggit(severity, message):
    """
    Write out error messages to our chosen locations.  If we get a
    severity of 'ERROR', then also exit with status code 1.
    """
    mypid = os.getpid()
    ts = datetime.datetime.fromtimestamp(
        time.time()).strftime('%Y-%m-%d_%H:%M:%S')
    loglocation = opt.logFile
    with open(loglocation, 'a+') as text_file:
        text_file.write(('[%s] %s %s: %s\n') % (mypid, ts, severity, message))
    if opt.debug:
        print(('[%s] %s %s: %s') % (mypid, ts, severity, message))
    if severity == 'NOTICE':
        sys.stderr.write('%s: %s\n' % (severity, message))
    if severity == 'SUCCESS':
        sys.stderr.write('%s: %s\n' % (severity, message))
        syslog.syslog(syslog.LOG_INFO, "%s - %s: %s"
            % (os.path.basename(__file__), severity, message))
    if severity == 'ERROR':
        sys.stderr.write('%s: %s\n' % (severity, message))
        syslog.syslog(syslog.LOG_INFO, "%s - %s: %s"
            % (os.path.basename(__file__), severity, message))
        shutil.rmtree(tmpDir)
        sys.exit(1)

def parseConfig(file):
    """
    Load a json configuration from a configuration file.  Sets a global
    'config' variable.
    """
    global config

    try:
        config = json.load(open(file, 'r'))
    except IOError as e:
        print("file error:  %s" % e)
        sys.exit(2)
    except Exception as e:
        print("unknown error:  %s" % e)
        sys.exit(2)

    return config


def parseGroups(data):
    """
    Look at the 'groups' data from the json data, and generates a list of
    group entries:

        NAME:*:GID:USER,USER,USER,...

    Returns two items: an array of matching entries, and a count of
    entries that couldn't be parsed.
    """
    loggit('INFO', 'Processing groups list')
    shortlist = []
    newDict = {}
    skip = {}

    groups = data['groups']
    success = []
    numFailures = 0

    if 'groupIgnore' in config:
        for i in config['groupIgnore']:
            skip[i] = 1

    for groupname in groups:
        shortDict = groups[groupname]
        keyFailures = []
        for requiredElement in requiredElements:
            if requiredElement not in shortDict:
                keyFailures.append(requiredElement)

        if len(keyFailures) > 0:
            loggit('NOTICE', '%s: missing key(s): %s' % (groupname,
                ','.join(keyFailures)))
            numFailures += 1

        else:
            gid = str(shortDict['gid'])
            users = shortDict['users']

            groupEntry = '%s:*:%s:%s' % \
                (groupname, gid, users)

            if groupname in skip:
                loggit('NOTICE', '%s - skipping group (groupIgnore)' % groupname)
                numFailures += 1

            elif (re.search('^[a-z0-9_-]+$', groupname)
              and re.search('^[0-9]+$', gid)
              and isinstance(users, str)):
                shortlist.append(gid)

                if gid not in newDict:
                    newDict[gid] = []
                newDict[gid].append(groupEntry)
            else:
                loggit('NOTICE', '%s - could not parse (%s)'
                    % (groupname, shortDict))
                numFailures += 1

    shortlist = list(set(shortlist))
    shortlist.sort(key=int)
    for gid in shortlist:
        e = newDict[gid]
        for i in e:
            success.append(i)

    return success, numFailures

def populateGroupsFile(data, success):
    """
    Populate /etc/sssd/group (or equivalent).  We do some checks to confirm
    that everything wrote out properly before we actually drop the file
    into place.
    """

    ts = datetime.datetime.fromtimestamp(
        data['generationTime']).strftime('%Y%m%d_%H-%M-%S')

    tmpFile = '%s/sanitized-group-%s.txt' % (tmpDir, ts)

    final = opt.file
    finalBak = final + '.bak'

    loggit('INFO', '%s: creating file and populating' % tmpFile)
    with open(tmpFile, 'w') as text_file:
        for item in success:
            text_file.write('%s\n' % item)

    loggit('INFO', '%s: validating' % tmpFile)
    if os.path.isfile(tmpFile):
        num_lines = sum(1 for line in open(tmpFile))
        if num_lines == len(success):
            loggit('INFO', '%s: correct number of entries (%s)'
                % (tmpFile, len(success)))
        else:
            loggit('ERROR', '%s: contains %s entries, should be %s'
                % (tmpFile, num_lines, len(success)))
    else:
        loggit('ERROR', '%s: file not found' % (tmpFile))

    if os.path.isfile(final):
        if filecmp.cmp(tmpFile, final):
            loggit('INFO', '%s and %s are identical, no updating' % (tmpFile, final))
            return
    else:
        loggit('INFO', 'no old file at %s, no backup' % (final))

    if os.path.isfile(final):
        loggit('INFO', 'cp %s %s' % (final, finalBak))
        shutil.copy2(final, finalBak)

    loggit('INFO', 'cp %s %s' % (tmpFile, final))
    shutil.copy2(tmpFile, final)

    loggit('INFO', '%s: database is complete' % (final))

def proxyOrEmpty():
    """
    Support proxies; assumes that the entry in the config file is
    accurate.
    """

    if 'proxies' in config: return config['proxies']
    else: return {}

def retrieveJson(url):
    """
    Pull down a json-formatted file from a URL, and returns a requestUrl
    data object.
    """
    try:
        requestURL = requests.get(url, verify=False, timeout=4.00,
            proxies=proxyOrEmpty())
        if StrictVersion(requests.__version__) > StrictVersion('1.0.0'):
            data = requestURL.json()
        else:
            data = requestURL.json
    except:
        loggit('ERROR', 'failure while retrieving json data from URL (%s)'
            % (url))

    loggit('INFO', 'retrieved URL (%s)' % (url))
    return data

def validateMetadata(data):
    """
    Confirms that required fields are all present in the json data.
    Returns an error string or, if everything is okay, an empty string.
    """
    if 'generationTime' in data:
        if isinstance(data['generationTime'], float) or \
           isinstance(data['generationTime'], int):
            pass
        else:
            return 'generationTime: must be a float or an int'
    else:
        return 'generationTime: required field not present'

    if 'numberOfGroups' in data:
        if isinstance(data['numberOfGroups'], int):
            if data['numberOfGroups'] <= 0:
                return 'numberOfGroups: must be greater than 0'
        else:
            return 'numberOfGroups: must be an integer'
    else:
        return 'numberOfGroups: required field not present'

    if 'groups' in data: pass
    else:
        return 'groups: required hash is empty'

    return ''


#########################################################################
### main () #############################################################
#########################################################################

def main():
    parseConfig(configFile)

    usage = "%prog [options]"
    p = optparse.OptionParser(usage=usage,
        description="fetch group database data, write to raw group file")
    p.add_option('--file', dest='file', action='store',
        default=config['groupFileRaw'], help='%default')
    p.add_option('--debug', dest='debug', action='store_true',
        help='set to print debugging information')
    p.add_option('--logFile', dest='logFile', action='store',
        default=config['logFile'], help='%default')
    p.add_option('--test', dest='test', action='store_true', default=False,
        help='if set, print output to STDOUT; default: %default')
    p.add_option('--url', dest='url', action='store',
        default=config['groupUrl'], help='%default')
    p.add_option('--workDir', dest='workDir', action='store',
        default=config['workDir'], help='%default')

    global opt
    opt, args = p.parse_args()

    data = retrieveJson(opt.url)
    try:
        error = validateMetadata(data)
        if error != '': loggit('ERROR', error)

        (success, numFailures) = parseGroups(data)
        numSuccess = len(success)

        loggit('INFO', 'Number of good groups [%s]' % (numSuccess))
        loggit('INFO', 'Number of failed groups [%s]' % (numFailures))

        totalDetectedGroups = numSuccess + numFailures
        if totalDetectedGroups == data['numberOfGroups']:
            if (opt.test):
                for i in success: print(i)
            else:
                populateGroupsFile(data, success)
                loggit('SUCCESS', "%s - good [%s], failed [%s]"
                    % (opt.file, numSuccess, numFailures))

        else:
            loggit('ERROR',
                "group count (%s) does not match 'numberOfGroups' (%s)"
                % (totalDetectedGroups, data['numberOfGroups']))

        shutil.rmtree(tmpDir)
        sys.exit(0)

    except Exception as e:
        loggit('ERROR', '(Python Error) %s' % (str(e)))

if __name__ == "__main__":
    main()

#########################################################################
### POD Documentation ###################################################
#########################################################################
## We use this to generate man pages.

"""

=head1 NAME

json-fetchgroupfile - populate a raw group file from external json data

=head1 SYNOPSIS

B<json-fetchgroupfile> [options]

=head1 USAGE

json-fetchgroupfile pulls an external JSON-formatted list of Unix users,
converts it to a group file suitable for use with sss, and copies it
into place.  There are a variety of checks along the way to make sure
everything is working nicely.

=head1 OPTIONS

=over 4

=item I<--file> F<FILE>

Override the file we should run against.  Default: F</etc/sssd/group>

=item I<--debug>

If set, prints debugging information to STDOUT.

=item I<--logFile> F<FILE>

Where should we send log messages?  Default: F</var/log/json-passwd.log>

=item I<--test>

If set, print logging output to STDOUT as well.  Default: false.

=item I<--url> I<URL>

From where should we retrieve the data?  Default is in the config file.

=item I<--workDir> F<DIRECTORY>

Where should we store files by default?  Default is in the config file.

=back

=head1 INPUT

The JSON should contain the following fields:

=over 4

=item generationTime

What time was this data generated?  Contents: int or float,
number-of-seconds since epoch.

=item numberOfGroups

How many entries should be in the 'groups' field?  Contents: integer.

=item groups

A hash of group entries.  The key for each value is the group name (must
be a parseable string); each entry should contain:

=over 4

=item gid

String containing the numeric gid.

=item users

String containing all user entries.  Can be empty.

=back

=back

=head1 FILES

=over 4

=item F</etc/json-passwd/config>

JSON-formatted configuration file.  Can be overridden with the environment
variable I<JPCONF>.

=back

=head1 AUTHOR

Tim Skirvin <tskirvin@fnal.gov>

=head1 COPYRIGHT

Copyright 2015-2021, Fermi National Accelerator Laboratory

This program is free software; you may redistribute it and/or modify
it under the same terms as Perl itself.

=cut

"""
